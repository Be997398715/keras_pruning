相关视频及资料：https://github.com/jacobgil/pytorch-pruning
		https://blog.csdn.net/jacke121/article/details/79450321
		https://github.com/BenWhetton/keras-surgeon

论文中提出的方法：先将网络进行前向传播，然后取得每一层激活层的输出作为对卷积层的评价标准。将其L2范数经过排序后取N个最小值作为
		  要被剪枝的filter，然后剪去，再重新训练。这样在减小模型大小的同时，可以有效保证其精度。

剪枝： python pruning.py (剪枝并重新训练已有模型)
训练： python util.py (对模型进行数据加载及训练)
保存模型权重：logs/weights文件夹下
剪枝信息：logs/prune_informationweights文件夹下
相关论文：paper文件夹下

结果：  只做了一次剪枝操作：
       实际N=1024，一次性剪去 979 个卷积核，最终经过训练val_acc=0.917差不多等于原模型的acc=0.931，而模型减少了40%，效果良好

注意： 这个剪枝的方法有以下优缺点：
       优点：在原有模型霞可以有效保证精度并减小模型大小，可以减小内存开销
       缺点：在训练时需要内存开销大，需要足够的内存去训练，且比较耗时

       本代码相关注意：
       1. 没有更好的完善好代码，默认需要的网络是没有自己重命名过的，且只对卷积层进行剪枝
       2. 部分代码需要根据自己的模型层情况更改：pruning.py的line-107
       3. 还有一个bug是没有解决的，N虽然设置为512，但是实际因为一些逻辑问题(比如排名中分数重复但层数不同)没有得到很好
          解决，最终的剪枝卷积核 <= N


代码中使用的模型下载链接：链接：https://pan.baidu.com/s/1iV5WyIAXC-qsDZ82L14blA 
提取码：6x4g 

########################################################### ##########################
本次keras版本的剪枝复现成功，查了很多资料，都没有人做这个，本着共享和攻克难关的想法，
查阅了很多资料并手写代码调试bug，最终完成！ 
#######################################################################################
