相关视频及资料：https://github.com/jacobgil/pytorch-pruning
		https://blog.csdn.net/jacke121/article/details/79450321
		https://github.com/BenWhetton/keras-surgeon

论文中提出的方法：先将网络进行前向传播，然后取得每一层激活层的输出作为对卷积层的评价标准。将其L2范数经过排序后取N个最小值作为
		  要被剪枝的filter，然后剪去，再重新训练。这样在减小模型大小的同时，可以有效保证其精度。

剪枝： python pruning.py (剪枝并重新训练已有模型)
训练： python util.py (对模型进行数据加载及训练)
保存模型权重：logs/weights文件夹下
剪枝信息：logs/prune_informationweights文件夹下
相关论文：paper文件夹下

结果:  做了三次剪枝操作
       第一次N=1024，一次性剪去 979 个卷积核，最终经过训练val_acc=0.917差不多等于原模型的acc=0.931，而模型减少了40%，效果良好
       第二次N=1024，一次性剪去 854 个卷积核，出现训练集精度远小于测试集的情况，加大训练次数，减小weight_decay和dropout使其容
       易拟合，学习率不宜太大，最好<=0.001，最终经过训练val_acc=0.914差不多等于原模型的acc=0.931，而模型已经减少了67%
       第三次N=1024，一次性剪去 930 个卷积核，训练迭代次数更大，最终得到val_acc=0.85
       最终完成结果：acc：0.931 -> 0.876    模型大小：57.3 M -> 5.85M

注意： 代码中实际效果与学习率，迭代次数等等有关，请自行调整
       这个剪枝的方法有以下优缺点：
       优点：在原有模型霞可以有效保证精度并减小模型大小，可以减小内存开销
       缺点：在训练时需要内存开销大，需要足够的内存去训练，且比较耗时

       本代码相关注意：
       1. 没有更好的完善好代码，默认需要的网络是没有自己重命名过的，且只对卷积层进行剪枝
       2. 部分代码需要根据自己的模型层情况更改：pruning.py的line-107
       3. 还有一个bug是没有解决的，N虽然设置为512，但是实际因为一些逻辑问题(比如排名中分数重复但层数不同)没有得到很好
          解决，最终的剪枝卷积核 <= N


代码中使用的模型下载链接：https://pan.baidu.com/s/15Mub5KlEJMljd99S0yCzLA 
提取码：365s 

########################################################### ##########################
本次keras版本的剪枝复现成功，查了很多资料，都没有人做这个，本着共享和攻克难关的想法，
查阅了很多资料并手写代码调试bug，最终完成！ 
#######################################################################################
